## 模型

```
弱分类器选择CART TREE，总分类器是将每轮训练得到的弱分类器加权求和得到的。模型最终可描述为：
    $$F_m(x) = \sum_{m=1}^MT(x;\theta_m)$$
模型一共训练M轮，每轮产生一个弱分类器$$T(x;\theta_m)$$。弱分类器的损失函数为：
    $$\hat{\theta_m} = argmin_\theta_m\sum_{i=1}^NL(y_i,F_{m-1}(x_i)+T(x_i;\theta_m))$$
Fm−1(x)  为当前的模型，gbdt 通过经验风险极小化来确定下一个弱分类器的参数。具体到损失函数本身的选择也就是L的
```

选择，有平方损失函数，0-1损失函数，对数损失函数。  
    从损失函数角度来看GBDT：

* 一是希望损失函数能够不断减小，
* 二是希望损失函数能够尽快减小 $$\implies$$ 让损失函数沿着负方向梯度
  利用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值去拟合一个回归树。gbdt 每轮迭代的时
  候，都去拟合损失函数在当前模型下的负梯度。

## loss function

![](/assets/GBDT_Loss.png)

